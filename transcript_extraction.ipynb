{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08dcf386-768d-40cf-ac7b-36e6f7a170fa",
   "metadata": {},
   "source": [
    "TODO\n",
    "* ~Merge Tables 2,4,10 to work together~\n",
    "* ~Create loop for full season~\n",
    "* ~Add season and episode to front of data frame~\n",
    "\n",
    "Someday:\n",
    "* Fix Italics:\n",
    "    * Work: \n",
    "        * italic_text_with_suffix =  '12345' + italics.get_text(strip=True) + '12345'\n",
    "    * Not work: \n",
    "        * italic_text_with_suffix =  '12345' + italics.get_text(strip=True) + '12345'\n",
    "        \n",
    "Lessons Learned: \n",
    "* Look for specific class types in BeautifulSoup. The fact that the transcript was formated as a *wikitable* made life much easier\n",
    "* Figuring out Edge Cases can take a majority of work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d5bc47f-88c2-433e-80d5-4c9fb8e177ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "#standard\n",
    "import pandas as pd\n",
    "#import random\n",
    "from datetime import datetime\n",
    "from pandasql import sqldf\n",
    "pysqldf = lambda q: sqldf(q,globals())\n",
    "\n",
    "#Viz\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "#Data Pulls\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c837a8-d98c-42dc-abf5-6b87fb049837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 90 tables on the page.\n"
     ]
    }
   ],
   "source": [
    "#Base URL for Transcripts\n",
    "url_base = 'https://avatar.fandom.com/wiki/Avatar_Wiki:Transcripts'\n",
    "response = requests.get(url_base)\n",
    "\n",
    "#Count # of Tables of Transcript Page\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "tables = soup.find_all(\"table\")\n",
    "print(f\"Found {len(tables)} tables on the page.\")\n",
    "\n",
    "# Table 2: Book 1 Water\n",
    "# Table 4: Book 2 Earth\n",
    "# Table 10: Book 3 Fire\n",
    "\n",
    "# if len(tables) > 0:\n",
    "#     print(\"First table:\")\n",
    "#     print(tables[10].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c972c08f-fce0-42e9-88d7-8f80970e9e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_list = [2, #Water\n",
    "             5, #Earth\n",
    "             10] # Fire\n",
    "\n",
    "episode_list = []\n",
    "\n",
    "for book in book_list:\n",
    "    specific_table = soup.find_all(\"table\")[book]  # Replace 0 with the index of the table you want\n",
    "    links = specific_table.find_all(\"a\")\n",
    "    for link in links:\n",
    "        episode_list.append(link.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ecb95ae-fb85-4093-b529-977061278d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove url links for commentary links\n",
    "episode_list_filtered = [episode for episode in episode_list if \"commentary\" not in episode]\n",
    "#episode_list_filtered\n",
    "\n",
    "#Creates Episodes URLs\n",
    "base = 'https://avatar.fandom.com'\n",
    "url_episode_list = []\n",
    "for episode in episode_list_filtered:\n",
    "    #print(base + episode)\n",
    "    url_episode_list.append(base + episode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e82b324-2693-4fcd-af6e-94bb6d8013f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Edge Case Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374d4c67-b5ba-469c-b74b-a9bf93acfd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printe Edge Case Episodes\n",
    "for episode_number, url in enumerate(url_episode_list):\n",
    "    \n",
    "    split_text = url.split(':', 2)\n",
    "    episode_title = split_text[2]\n",
    "\n",
    "    episode_number += 1\n",
    "    # print(episode_number)\n",
    "    # print(episode_title)\n",
    "    # print(url)\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    # Parse the page with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all the tables with the class \"wikitable\"\n",
    "    wikitable_tables = soup.find_all(\"table\", class_=\"wikitable\")\n",
    "    num_tables = len(wikitable_tables)\n",
    "    \n",
    "    if num_tables >= 2:\n",
    "            print(episode_number)\n",
    "            print(episode_title)\n",
    "            print(url)\n",
    "            print(f\"Number of Tables: {len(wikitable_tables)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e9f5b0-7ab3-42a2-8ec8-d3192cbb92ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Edge Case Exploration\n",
    "\n",
    "#url = 'https://avatar.fandom.com/wiki/Transcript:The_Boy_in_the_Iceberg'\n",
    "# Index 1 | 2nd Table\n",
    "\n",
    "#url = 'https://avatar.fandom.com/wiki/Transcript:The_Avatar_Returns'\n",
    "# Index 1 2nd Table \n",
    "\n",
    "# url = 'https://avatar.fandom.com/wiki/Transcript:Bato_of_the_Water_Tribe'\n",
    "# Index 0 1st Table \n",
    "# 2nd Table contains a deleted scene\n",
    "\n",
    "#url = 'https://avatar.fandom.com/wiki/Transcript:The_Tales_of_Ba_Sing_Se'\n",
    "# Index 0 The Tale of Toph and Katara\n",
    "# Index 1 The Tale of Iroh\n",
    "# Index 2 The Tale of Aang\n",
    "# Index 3 The Tale of Sokka \n",
    "# Index 4 THe Tale of Zuko\n",
    "\n",
    "#url = 'https://avatar.fandom.com/wiki/Transcript:The_Puppetmaster'\n",
    "# Index 1 2nd Table \n",
    "# Removes the \"previously on Avatar\"\n",
    "    \n",
    "response = requests.get(url)\n",
    "ep_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "tables = ep_soup.select(\"table.wikitable\")\n",
    "\n",
    "data = []\n",
    "\n",
    "print(f\"Number of Tables: {len(tables)}\")\n",
    "print()\n",
    "\n",
    "desired_table = tables[:4]  \n",
    "# Find all rows within the 2nd Table that holds the transcript\n",
    "rows = desired_table.select(\"tbody tr\")\n",
    "\n",
    "for row in rows:\n",
    "    character_cell = row.find('th')  # Find the <th> for character names\n",
    "    dialogue_cell = row.find('td')    # Find the <td> for character's dialogue\n",
    "\n",
    "    if character_cell and dialogue_cell:  # Ensure both character & dialogue are present (thus skipping pure screen directions)\n",
    "        character = character_cell.get_text(strip=True)\n",
    "\n",
    "        # Replace <i> tags with their text (ITALICS CAUSING PROBLEMS)\n",
    "        for italics in dialogue_cell.find_all('i'):\n",
    "            # Get the text inside <i>, append '123' and replace the <i> with this text\n",
    "            italic_text_with_suffix =  '12345' + italics.get_text(strip=True) + '12345'\n",
    "            italics.replace_with(italic_text_with_suffix)  # Replace <i> tag with modified text\n",
    "\n",
    "        dialogue = dialogue_cell.get_text(strip=True)  # Get the text after modifying italics\n",
    "\n",
    "        data.append({'character': character, 'dialogue': dialogue})\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "#Cleaning\n",
    "df['dialogue'] = df['dialogue'].str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\n",
    "df['dialogue'] = df['dialogue'].str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "df['dialogue'] = df['dialogue'].str.replace('12345', ' ').str.strip()\n",
    "\n",
    "#Word Count\n",
    "df['word_count'] = df['dialogue'].str.split().apply(len)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc3e69a-4689-448c-a156-d4154dbc0ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tales of Ba Sing Se - Edge Case Exploration\n",
    "url = 'https://avatar.fandom.com/wiki/Transcript:The_Tales_of_Ba_Sing_Se'\n",
    "# Index 0 The Tale of Toph and Katara\n",
    "# Index 1 The Tale of Iroh\n",
    "# Index 2 The Tale of Aang\n",
    "# Index 3 The Tale of Sokka \n",
    "# Index 4 THe Tale of Zuko\n",
    "    \n",
    "response = requests.get(url)\n",
    "ep_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "tables = ep_soup.select(\"table.wikitable\")\n",
    "\n",
    "data = []\n",
    "\n",
    "# Iterate over the first 5 tables (0 to 4)\n",
    "for table in tables[:5]:  \n",
    "    # Find all rows within each table\n",
    "    rows = table.select(\"tbody tr\")\n",
    "\n",
    "    for row in rows:\n",
    "        character_cell = row.find('th')  # Find the <th> for character names\n",
    "        dialogue_cell = row.find('td')   # Find the <td> for character's dialogue\n",
    "\n",
    "        if character_cell and dialogue_cell:  # Ensure both character & dialogue are present\n",
    "            character = character_cell.get_text(strip=True)\n",
    "\n",
    "            # Process the <i> tags within the dialogue\n",
    "            for italics in dialogue_cell.find_all('i'):\n",
    "                # Prepend and append '12345' to italicized text\n",
    "                italic_text_with_suffix = '12345' + italics.get_text(strip=True) + '12345'\n",
    "                italics.replace_with(italic_text_with_suffix)  # Replace <i> tag with modified text\n",
    "\n",
    "            # Get the full dialogue text after modifications\n",
    "            dialogue = dialogue_cell.get_text(strip=True)\n",
    "\n",
    "            # Append the data to the list\n",
    "            data.append({'character': character, 'dialogue': dialogue})\n",
    "\n",
    "# Convert the collected data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "#Cleaning\n",
    "df['dialogue'] = df['dialogue'].str.replace(r'\\[.*?\\]', '', regex=True).str.strip()\n",
    "df['dialogue'] = df['dialogue'].str.replace(r'\\(.*?\\)', '', regex=True).str.strip()\n",
    "df['dialogue'] = df['dialogue'].str.replace('12345', ' ').str.strip()\n",
    "\n",
    "#Word Count\n",
    "df['word_count'] = df['dialogue'].str.split().apply(len)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b3912-64b7-4f48-9120-73bf40876aa0",
   "metadata": {},
   "source": [
    "### Full Series Trancript Pull\n",
    "* Includes all Non Edge Cases\n",
    "* All edge cases including:\n",
    "    * Where primary table is index 1 (rather than index 0) \n",
    "    * Tales of Ba Sing Se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1441b3a-7b65-4216-80fa-81762e2a10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#episodes, so technically need to subtract 1 from each to get the edge case\n",
    "edge_case_episodes = [1, #The_Boy_in_the_Iceberg\n",
    "                      2, #The_Avatar_Returns\n",
    "                      #15, #Bato_of_the_Water_Tribe - Use table 1, index 0 to remove deleted scence\n",
    "                      35, #The_Tales_of_Ba_Sing_Se\n",
    "                      48 #The_Puppetmaster\n",
    "                     ]\n",
    "\n",
    "#Subtract 1 from each episode to convert episode_number --> index\n",
    "edge_case_episodes = [episode - 1 for episode in edge_case_episodes]\n",
    "#print(edge_case_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78dd7083-a913-4c58-aab2-4d239b74fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df = pd.DataFrame()\n",
    "\n",
    "for episode_number, url in enumerate(url_episode_list):\n",
    "    # Splits based on Edge Cases\n",
    "    \n",
    "    data = []  # Initialize data list for an individual episode\n",
    "    \n",
    "    # If Statement splits data into base and non-edge cases\n",
    "    if episode_number not in edge_case_episodes:\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        ep_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        tables = ep_soup.select(\"table.wikitable\")\n",
    "        \n",
    "        desired_table = tables[0]\n",
    "        rows = desired_table.select(\"tbody tr\")\n",
    "\n",
    "    if episode_number in edge_case_episodes:\n",
    "            \n",
    "            if episode_number != 34:\n",
    "                response = requests.get(url)\n",
    "                ep_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "                tables = ep_soup.select(\"table.wikitable\")\n",
    "                \n",
    "                desired_table = tables[1]\n",
    "                rows = desired_table.select(\"tbody tr\")\n",
    "                \n",
    "            else:\n",
    "                response = requests.get(url)\n",
    "                ep_soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "                tables = ep_soup.select(\"table.wikitable\")\n",
    "                \n",
    "                all_rows = []  # Initialize list to store all rows from all tables\n",
    "\n",
    "                for table in tables[:5]:\n",
    "                    table_rows = table.select(\"tbody tr\")\n",
    "                    all_rows.extend(table_rows)  # Append all rows to the all_rows list\n",
    "                    \n",
    "                rows = all_rows  # Now, 'rows' contains all the rows from tables 0 to 4\n",
    "                    \n",
    "    split_text = url.split(':', 2)\n",
    "    episode_title = split_text[2]\n",
    "    episode_number += 1\n",
    "    \n",
    "    # print(episode_number)\n",
    "    # print(episode_title)\n",
    "    # print(url)\n",
    "    # print()\n",
    "\n",
    "    for row in rows:\n",
    "        character_cell = row.find('th')  # Find the <th> for character names\n",
    "        dialogue_cell = row.find('td')   # Find the <td> for character's dialogue\n",
    "\n",
    "        if character_cell and dialogue_cell:  # Ensure both character & dialogue are present\n",
    "            character = character_cell.get_text(strip=True)\n",
    "\n",
    "            # Replace <i> tags with their text (handle italicized text)\n",
    "            for italics in dialogue_cell.find_all('i'):\n",
    "                italic_text_with_suffix = '12345' + italics.get_text(strip=True) + '12345'\n",
    "                italics.replace_with(italic_text_with_suffix)  # Replace <i> tag with modified text\n",
    "\n",
    "            dialogue = dialogue_cell.get_text(strip=True)  # Get the text after modifying italics\n",
    "            data.append({'character': character, 'dialogue': dialogue})\n",
    "\n",
    "    # Create DataFrame if the data was extracted\n",
    "    if data:\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Cleaning the dialogue column\n",
    "        df['dialogue'] = df['dialogue'].str.replace(r'\\[.*?\\]', '', regex=True).str.strip()  # Remove text in []\n",
    "        df['dialogue'] = df['dialogue'].str.replace(r'\\(.*?\\)', '', regex=True).str.strip()  # Remove text in ()\n",
    "        df['dialogue'] = df['dialogue'].str.replace('12345', ' ').str.strip()  # Replace '12345' with space\n",
    "\n",
    "        # Add word count\n",
    "        df['word_count'] = df['dialogue'].str.split().apply(len)\n",
    "\n",
    "        # Add episode number and title\n",
    "        df['abs_episode'] = episode_number\n",
    "        df['episode_title'] = episode_title \n",
    "\n",
    "        # Concatenate with the main transcript DataFrame\n",
    "        transcript_df = pd.concat([transcript_df, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9ac96e-ded5-40b1-8bf4-1080d65810b3",
   "metadata": {},
   "source": [
    "### Edge Case Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f99494-e24c-4105-9623-0a803cf9a30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df[transcript_df['episode'] ==2].head(126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc8a24d-2465-4037-b5c3-b196a1630d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df[transcript_df['episode'] ==35].head(126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2532830e-7fa3-4327-8b54-323df3b03c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df[transcript_df['episode'] ==48].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5ddcb3-7813-4901-9dad-e135320d1ac0",
   "metadata": {},
   "source": [
    "### Transcript Finalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed25336-2151-45ca-9855-e82ba8e129fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93392a53-0d83-45d2-86d9-409b2dafac6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import unquote\n",
    "#Replace apostrophes \n",
    "transcript_df['episode_title'] = transcript_df['episode_title'].apply(lambda x: unquote(x))\n",
    "\n",
    "#Replace '_(episode)'\n",
    "transcript_df['episode_title'] = transcript_df['episode_title'].str.replace('_(episode)', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7caf9eb9-7be7-44bc-82ba-c61c2d983dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_season_mapping = {\n",
    "    'The_Boy_in_the_Iceberg': (1, 1),\n",
    "    'The_Avatar_Returns': (1, 2),\n",
    "    'The_Southern_Air_Temple': (1, 3),\n",
    "    'The_Warriors_of_Kyoshi': (1, 4),\n",
    "    'The_King_of_Omashu': (1, 5),\n",
    "    'Imprisoned': (1, 6),\n",
    "    'Winter_Solstice,_Part_1:_The_Spirit_World': (1, 7),\n",
    "    'Winter_Solstice,_Part_2:_Avatar_Roku': (1, 8),\n",
    "    'The_Waterbending_Scroll': (1, 9),\n",
    "    'Jet': (1, 10),\n",
    "    'The_Great_Divide': (1, 11),\n",
    "    'The_Storm': (1, 12),\n",
    "    'The_Blue_Spirit': (1, 13),\n",
    "    'The_Fortuneteller': (1, 14),\n",
    "    'Bato_of_the_Water_Tribe': (1, 15),\n",
    "    'The_Deserter': (1, 16),\n",
    "    'The_Northern_Air_Temple': (1, 17),\n",
    "    'The_Waterbending_Master': (1, 18),\n",
    "    'The_Siege_of_the_North,_Part_1': (1, 19),\n",
    "    'The_Siege_of_the_North,_Part_2': (1, 20),\n",
    "    'The_Avatar_State': (2, 1),\n",
    "    'The_Cave_of_Two_Lovers': (2, 2),\n",
    "    'Return_to_Omashu': (2, 3),\n",
    "    'The_Swamp': (2, 4),\n",
    "    'Avatar_Day': (2, 5),\n",
    "    'The_Blind_Bandit': (2, 6),\n",
    "    'Zuko_Alone': (2, 7),\n",
    "    'The_Chase': (2, 8),\n",
    "    'Bitter_Work': (2, 9),\n",
    "    'The_Library': (2, 10),\n",
    "    'The_Desert': (2, 11),\n",
    "    \"The_Serpent's_Pass\": (2, 12),\n",
    "    'The_Drill': (2, 13),\n",
    "    'City_of_Walls_and_Secrets': (2, 14),\n",
    "    'The_Tales_of_Ba_Sing_Se': (2, 15),\n",
    "    \"Appa's_Lost_Days\": (2, 16),\n",
    "    'Lake_Laogai': (2, 17),\n",
    "    'The_Earth_King': (2, 18),\n",
    "    'The_Guru': (2, 19),\n",
    "    'The_Crossroads_of_Destiny': (2, 20),\n",
    "    'The_Awakening': (3, 1),\n",
    "    'The_Headband': (3, 2),\n",
    "    'The_Painted_Lady': (3, 3),\n",
    "    \"Sokka's_Master\": (3, 4),\n",
    "    'The_Beach': (3, 5),\n",
    "    'The_Avatar_and_the_Fire_Lord': (3, 6),\n",
    "    'The_Runaway': (3, 7),\n",
    "    'The_Puppetmaster': (3, 8),\n",
    "    'Nightmares_and_Daydreams': (3, 9),\n",
    "    'The_Day_of_Black_Sun,_Part_1:_The_Invasion': (3, 10),\n",
    "    'The_Day_of_Black_Sun,_Part_2:_The_Eclipse': (3, 11),\n",
    "    'The_Western_Air_Temple': (3, 12),\n",
    "    'The_Firebending_Masters': (3, 13),\n",
    "    'The_Boiling_Rock,_Part_1': (3, 14),\n",
    "    'The_Boiling_Rock,_Part_2': (3, 15),\n",
    "    'The_Southern_Raiders': (3, 16),\n",
    "    'The_Ember_Island_Players': (3, 17),\n",
    "    \"Sozin's_Comet,_Part_1:_The_Phoenix_King\": (3, 18),\n",
    "    \"Sozin's_Comet,_Part_2:_The_Old_Masters\": (3, 19),\n",
    "    \"Sozin's_Comet,_Part_3:_Into_the_Inferno\": (3, 20),\n",
    "    \"Sozin's_Comet,_Part_4:_Avatar_Aang\": (3, 21),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7a415e-bdf5-4914-a786-ffdb3c229dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df['season'] = transcript_df['episode_title'].map(lambda x: episode_season_mapping.get(x, (None, None))[0])\n",
    "transcript_df['episode_number'] = transcript_df['episode_title'].map(lambda x: episode_season_mapping.get(x, (None, None))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "759586d2-ad35-4a66-a58c-14db4dea42ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>dialogue</th>\n",
       "      <th>word_count</th>\n",
       "      <th>abs_episode</th>\n",
       "      <th>episode_title</th>\n",
       "      <th>season</th>\n",
       "      <th>episode_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Sokka</td>\n",
       "      <td>Let's see your bison fly now, air boy.</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>The_Avatar_Returns</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>Warden</td>\n",
       "      <td>Show no mercy!</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Imprisoned</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>Shyu</td>\n",
       "      <td>A few weeks ago, an amazing thing occurred. Th...</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "      <td>Winter_Solstice,_Part_2:_Avatar_Roku</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>Gan Jin leader</td>\n",
       "      <td>See! We're going to become part of the food ch...</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>The_Great_Divide</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>Zhao</td>\n",
       "      <td>Uhh, no. Tell me, how does it feel to be the o...</td>\n",
       "      <td>82</td>\n",
       "      <td>13</td>\n",
       "      <td>The_Blue_Spirit</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3525</th>\n",
       "      <td>Fong</td>\n",
       "      <td>So, it's decided then. I'll help you figure ou...</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>The_Avatar_State</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>Due</td>\n",
       "      <td>You want me to eat old Slim? He's like a membe...</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>The_Swamp</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7658</th>\n",
       "      <td>Toph</td>\n",
       "      <td>Of course you do.  And that's why this wanted ...</td>\n",
       "      <td>17</td>\n",
       "      <td>47</td>\n",
       "      <td>The_Runaway</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>Katara</td>\n",
       "      <td>But we were too late. When we got there, the m...</td>\n",
       "      <td>17</td>\n",
       "      <td>56</td>\n",
       "      <td>The_Southern_Raiders</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9719</th>\n",
       "      <td>Bumi</td>\n",
       "      <td>Wait! Someone's missing from your group.  Some...</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>Sozin's_Comet,_Part_2:_The_Old_Masters</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           character                                           dialogue  \\\n",
       "178            Sokka             Let's see your bison fly now, air boy.   \n",
       "994           Warden                                     Show no mercy!   \n",
       "1247            Shyu  A few weeks ago, an amazing thing occurred. Th...   \n",
       "1849  Gan Jin leader  See! We're going to become part of the food ch...   \n",
       "2201            Zhao  Uhh, no. Tell me, how does it feel to be the o...   \n",
       "3525            Fong  So, it's decided then. I'll help you figure ou...   \n",
       "4120             Due  You want me to eat old Slim? He's like a membe...   \n",
       "7658            Toph  Of course you do.  And that's why this wanted ...   \n",
       "9229          Katara  But we were too late. When we got there, the m...   \n",
       "9719            Bumi  Wait! Someone's missing from your group.  Some...   \n",
       "\n",
       "      word_count  abs_episode                           episode_title  season  \\\n",
       "178            8            2                      The_Avatar_Returns       1   \n",
       "994            3            6                              Imprisoned       1   \n",
       "1247          18            8    Winter_Solstice,_Part_2:_Avatar_Roku       1   \n",
       "1849          13           11                        The_Great_Divide       1   \n",
       "2201          82           13                         The_Blue_Spirit       1   \n",
       "3525          22           21                        The_Avatar_State       2   \n",
       "4120          14           24                               The_Swamp       2   \n",
       "7658          17           47                             The_Runaway       3   \n",
       "9229          17           56                    The_Southern_Raiders       3   \n",
       "9719          11           59  Sozin's_Comet,_Part_2:_The_Old_Masters       3   \n",
       "\n",
       "      episode_number  \n",
       "178                2  \n",
       "994                6  \n",
       "1247               8  \n",
       "1849              11  \n",
       "2201              13  \n",
       "3525               1  \n",
       "4120               4  \n",
       "7658               7  \n",
       "9229              16  \n",
       "9719              19  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.sample(10).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fbc08be-5a2c-43be-a202-73f676163054",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df.to_csv('full_transcript.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccd307-91a2-4e4b-9e98-f18e5f464eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
